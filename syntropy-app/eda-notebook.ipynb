{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b08b8c9-e305-486e-93e3-d4b7e91c031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e90f3b-7001-43cd-8bc6-bb4e7fee458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define API endpoints\n",
    "CODE_SUMMARIZATION_URL = \"http://localhost:8080/syntropy/code/summarize\"\n",
    "REQUIREMENTS_SUMMARIZATION_URL = \"http://localhost:8080/syntropy/requirements/summarize\"\n",
    "COMPARISON_SUMMARIZATION_URL = \"http://localhost:8080/syntropy/comparison/summarize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b36b3313-0fc2-4a9d-9d3d-c0498fb48fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "RESULTS_DIR = \"dataset_results\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b4ec393-4e95-4d3c-ad46-510c0dcbfb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if dataset pair has already been processed\n",
    "def is_already_processed(dp_id):\n",
    "    result_dir = os.path.join(RESULTS_DIR, str(dp_id))\n",
    "    return os.path.exists(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cacb0543-1d07-4449-8b6d-47b694647a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 1\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 2\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 3\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 4\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 5\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 6\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 7\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 8\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 9\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 10\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 11\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 12\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 13\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 14\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 15\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 16\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 17\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 18\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 19\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 20\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 21\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Skipping already processed Dataset Pair ID: 22\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "dict_keys(['', 'Dataset Pair ID', 'Requirements', 'Code Block(s)'])\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     55\u001b[39m             time.sleep(\u001b[32m5\u001b[39m)\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mProcessing complete.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[43mrun_syntropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mrun_syntropy\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mHitting the comparison summarization endpoint...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Hit the comparison summarization endpoint\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m comparison_response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mCOMPARISON_SUMMARIZATION_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcode_summary\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_summary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrequirements_summary\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequirements_summary\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m comparison_summary = comparison_response.json()\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(result_path, \u001b[33m\"\u001b[39m\u001b[33mcomparison_summarization.json\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/syntropy-app-KmLYymlh-py3.13/lib/python3.13/site-packages/requests/api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/syntropy-app-KmLYymlh-py3.13/lib/python3.13/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/syntropy-app-KmLYymlh-py3.13/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/syntropy-app-KmLYymlh-py3.13/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/syntropy-app-KmLYymlh-py3.13/lib/python3.13/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/syntropy-app-KmLYymlh-py3.13/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/syntropy-app-KmLYymlh-py3.13/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/syntropy-app-KmLYymlh-py3.13/lib/python3.13/site-packages/urllib3/connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Load CSV and process each row\n",
    "\n",
    "def run_syntropy():\n",
    "    with open(\"dataset.csv\", \"r\", newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            print(row.keys())\n",
    "            if not \"Dataset Pair ID\" in row.keys():\n",
    "                continue\n",
    "            dataset_pair_id = row[\"Dataset Pair ID\"]\n",
    "            code_block = row[\"Code Block(s)\"]\n",
    "            requirements = row[\"Requirements\"]\n",
    "    \n",
    "            if is_already_processed(dataset_pair_id):\n",
    "                print(f\"Skipping already processed Dataset Pair ID: {dataset_pair_id}\")\n",
    "                continue\n",
    "    \n",
    "            # Create a directory for each dataset_pair_id\n",
    "            result_path = os.path.join(RESULTS_DIR, dataset_pair_id)\n",
    "            os.makedirs(result_path, exist_ok=True)\n",
    "    \n",
    "            print('Hitting the code summarization endpoint...')\n",
    "            # Hit the code summarization endpoint\n",
    "            code_response = requests.post(CODE_SUMMARIZATION_URL, json={\"diffs\": code_block})\n",
    "            code_summary = code_response.json()\n",
    "            with open(os.path.join(result_path, \"code_summarization.json\"), \"w\", encoding='utf-8') as f:\n",
    "                json.dump(code_summary, f, indent=2)\n",
    "    \n",
    "            print('Done.')\n",
    "    \n",
    "            print('Hitting the requirements summarization endpoint...')\n",
    "            # Hit the requirements summarization endpoint\n",
    "            requirements_response = requests.post(REQUIREMENTS_SUMMARIZATION_URL, json={\"requirements\": requirements})\n",
    "            requirements_summary = requirements_response.json()\n",
    "            with open(os.path.join(result_path, \"requirements_summarization.json\"), \"w\", encoding='utf-8') as f:\n",
    "                json.dump(requirements_summary, f, indent=2)\n",
    "    \n",
    "            print('Done.')\n",
    "    \n",
    "            print('Hitting the comparison summarization endpoint...')\n",
    "            # Hit the comparison summarization endpoint\n",
    "            comparison_response = requests.post(\n",
    "                COMPARISON_SUMMARIZATION_URL,\n",
    "                json={\n",
    "                    \"code_summary\": code_summary,\n",
    "                    \"requirements_summary\": requirements_summary\n",
    "                }\n",
    "            )\n",
    "            comparison_summary = comparison_response.json()\n",
    "            with open(os.path.join(result_path, \"comparison_summarization.json\"), \"w\", encoding='utf-8') as f:\n",
    "                json.dump(comparison_summary, f, indent=2)\n",
    "    \n",
    "            print('Done.')\n",
    "    \n",
    "            time.sleep(5)\n",
    "    \n",
    "    print(\"Processing complete.\")\n",
    "\n",
    "run_syntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "00fbc0ad-de54-482d-b920-5ce44d3616c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_singleton_analysis(dp_id):\n",
    "    with open(\"dataset.csv\", \"r\", newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        processed = False\n",
    "        for row in reader:\n",
    "            #print(row.keys())\n",
    "            if not \"Dataset Pair ID\" in row.keys():\n",
    "                continue\n",
    "                \n",
    "            dataset_pair_id = row[\"Dataset Pair ID\"]\n",
    "            code_block = row[\"Code Block(s)\"]\n",
    "            requirements = row[\"Requirements\"]\n",
    "    \n",
    "            if str(dp_id) != dataset_pair_id:\n",
    "                continue\n",
    "    \n",
    "            print('---REQUIREMENTS:---')\n",
    "            print(requirements)\n",
    "            print()\n",
    "            \n",
    "            print('---CODE BLOCK:---')\n",
    "            print(code_block)\n",
    "            print()\n",
    "    \n",
    "            print('---SYNTHESIS:---')\n",
    "            \n",
    "            summary_file = \"comparison_summarization.json\"\n",
    "            \n",
    "            json_filename = f'{RESULTS_DIR}/{dataset_pair_id}/{summary_file}'\n",
    "            try:\n",
    "                with open(json_filename) as f:\n",
    "                    d = json.load(f)\n",
    "                    print(json.dumps(d, indent=4))\n",
    "\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"Synthesis for Dataset Pair ID has not been processed yet: {dp_id}\")\n",
    "                print()\n",
    "                \n",
    "            processed = True\n",
    "    if not processed:\n",
    "        print(f\"Dataset Pair ID {dp_id} has not been processed yet, or does not exist.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "28bdc97e-e4cf-4f2b-a40d-8c7378b424cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---REQUIREMENTS:---\n",
      "The application must enforce data immutability for critical objects and implement a custom serialization mechanism to ensure secure data exchange. Integration with our custom build system is required, and efforts should be made to improve existing documentation.\n",
      "\n",
      "---CODE BLOCK:---\n",
      "# Custom build system integration\n",
      "# Note: This code lacks thorough documentation.\n",
      "class ImmutableData:\n",
      "    def __init__(self, data):\n",
      "        self._data = tuple(data)  # using immutable tuple to store data\n",
      "\n",
      "    def serialize(self):\n",
      "        # Custom serialization: convert data to a comma-separated string\n",
      "        return ','.join(map(str, self._data))\n",
      "\n",
      "    @classmethod\n",
      "    def deserialize(cls, data_str):\n",
      "        # Custom deserialization\n",
      "        data = tuple(data_str.split(','))\n",
      "        return cls(data)\n",
      "\n",
      "data_obj = ImmutableData([1, 2, 3])\n",
      "serialized = data_obj.serialize()\n",
      "new_obj = ImmutableData.deserialize(serialized)\n",
      "print(serialized)\n",
      "\n",
      "---SYNTHESIS:---\n",
      "{\n",
      "    \"core_business_functionality\": {\n",
      "        \"did_right\": \"The code contributes to the product by enabling a simple way to store and retrieve data in a specific format using custom serialization/deserialization.\",\n",
      "        \"did_wrong\": \"Without specific requirements about the application's purpose, it is impossible to determine if the implementation aligns with the core business functionality.\",\n",
      "        \"ambiguous\": \"It's unclear how well the comma-separated string format suits the application needs without knowing the data's nature and use cases.\"\n",
      "    },\n",
      "    \"structural_and_modular_requirements\": {\n",
      "        \"did_right\": \"The single class structure is reasonable for a simple data handling task.\",\n",
      "        \"did_wrong\": \"Modularity is limited; the serialization/deserialization logic could be in a separate module if reused elsewhere.\",\n",
      "        \"ambiguous\": \"Whether the single-class structure is appropriate depends on the overall application architecture, which is unknown.\"\n",
      "    },\n",
      "    \"performance_and_scalability_criteria\": {\n",
      "        \"did_right\": \"Performance is likely not an issue for small datasets.\",\n",
      "        \"did_wrong\": \"The comma-separated string serialization method may become a bottleneck with large datasets.\",\n",
      "        \"ambiguous\": \"Scalability performance remains undetermined until testing with larger datasets is done.\"\n",
      "    },\n",
      "    \"data_handling_and_integrity\": {\n",
      "        \"did_right\": \"Data immutability is enforced using a tuple.\",\n",
      "        \"did_wrong\": \"Error handling for malformed serialized strings could be improved.\",\n",
      "        \"ambiguous\": \"Robustness is dependent on input string validation during deserialization. The validation is implicit instead of explicit.\"\n",
      "    },\n",
      "    \"error_handling_and_user_experience\": {\n",
      "        \"did_right\": \"N/A\",\n",
      "        \"did_wrong\": \"Minimal error handling. Exceptions during deserialization are not caught which can lead to crashes or data corruption.\",\n",
      "        \"ambiguous\": \"User impact of errors is uncertain without knowing the application's user interface and workflow.\"\n",
      "    },\n",
      "    \"efficiency_requirements_for_product_use_cases\": {\n",
      "        \"did_right\": \"Efficiency is adequate for small datasets.\",\n",
      "        \"did_wrong\": \"Alternative serialization methods might be required for larger datasets.\",\n",
      "        \"ambiguous\": \"The efficiency appropriateness depends on the specific use cases and data sizes, which are unknown.\"\n",
      "    },\n",
      "    \"readability_maintainability_and_team_adoption\": {\n",
      "        \"did_right\": \"The code is reasonably readable and maintainable in its current form.\",\n",
      "        \"did_wrong\": \"Missing docstrings and less descriptive variable names hinder readability and maintainability.\",\n",
      "        \"ambiguous\": \"Team adoption is dependent on proper documentation and coding style consistency which are not currently addressed.\"\n",
      "    },\n",
      "    \"testing_and_validation_criteria\": {\n",
      "        \"did_right\": \"N/A\",\n",
      "        \"did_wrong\": \"No unit tests are provided to cover various scenarios and edge cases. The provided example is not sufficient for validation.\",\n",
      "        \"ambiguous\": \"Validation is reliant on unknown product requirements, and test strategy is not clear.\"\n",
      "    },\n",
      "    \"external_dependencies_and_integrations\": {\n",
      "        \"did_right\": \"No external dependencies besides Python built-in libraries.\",\n",
      "        \"did_wrong\": \"Integration with a custom build system is a required feature that has not been implemented.\",\n",
      "        \"ambiguous\": \"The method of integration is not described.\"\n",
      "    },\n",
      "    \"security_standards_and_threat_mitigation\": {\n",
      "        \"did_right\": \"Custom serialization mechanism aids in secure data exchange.\",\n",
      "        \"did_wrong\": \"No explicit encryption or validation to prevent injection attacks from untrusted sources.\",\n",
      "        \"ambiguous\": \"Further security is dependent on sensitive data handled.\"\n",
      "    },\n",
      "    \"compliance_and_regulatory_considerations\": {\n",
      "        \"did_right\": \"N/A\",\n",
      "        \"did_wrong\": \"No explicit compliance steps are taken in the code.\",\n",
      "        \"ambiguous\": \"The need for compliance is dependent on data sensitivity, such as PII.\"\n",
      "    },\n",
      "    \"adherence_to_standards_and_best_practices\": {\n",
      "        \"did_right\": \"Basic Python coding conventions are followed.\",\n",
      "        \"did_wrong\": \"Missing docstrings and style guide adherence.\",\n",
      "        \"ambiguous\": \"Style consistency is uncertain.\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "run_singleton_analysis(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb5521a-fe2c-404c-8d4a-067eae8829c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf2fb7-e1f2-41aa-91b2-03ec11da0c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c4b883-2189-4bb8-9699-ef3e69a99fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
