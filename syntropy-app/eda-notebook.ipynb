{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b08b8c9-e305-486e-93e3-d4b7e91c031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e90f3b-7001-43cd-8bc6-bb4e7fee458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define API endpoints\n",
    "CODE_SUMMARIZATION_URL = \"http://localhost:8080/syntropy/code/summarize\"\n",
    "REQUIREMENTS_SUMMARIZATION_URL = \"http://localhost:8080/syntropy/requirements/summarize\"\n",
    "COMPARISON_SUMMARIZATION_URL = \"http://localhost:8080/syntropy/comparison/summarize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b36b3313-0fc2-4a9d-9d3d-c0498fb48fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "RESULTS_DIR = \"dataset_results\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b4ec393-4e95-4d3c-ad46-510c0dcbfb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if dataset pair has already been processed\n",
    "def is_already_processed(dp_id):\n",
    "    result_dir = os.path.join(RESULTS_DIR, str(dp_id))\n",
    "    return os.path.exists(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cacb0543-1d07-4449-8b6d-47b694647a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping already processed Dataset Pair ID: 1\n",
      "Skipping already processed Dataset Pair ID: 2\n",
      "Skipping already processed Dataset Pair ID: 3\n",
      "Skipping already processed Dataset Pair ID: 4\n",
      "Skipping already processed Dataset Pair ID: 5\n",
      "Skipping already processed Dataset Pair ID: 6\n",
      "Skipping already processed Dataset Pair ID: 7\n",
      "Skipping already processed Dataset Pair ID: 8\n",
      "Skipping already processed Dataset Pair ID: 9\n",
      "Skipping already processed Dataset Pair ID: 10\n",
      "Skipping already processed Dataset Pair ID: 11\n",
      "Skipping already processed Dataset Pair ID: 12\n",
      "Skipping already processed Dataset Pair ID: 13\n",
      "Skipping already processed Dataset Pair ID: 14\n",
      "Skipping already processed Dataset Pair ID: 15\n",
      "Skipping already processed Dataset Pair ID: 16\n",
      "Skipping already processed Dataset Pair ID: 17\n",
      "Skipping already processed Dataset Pair ID: 18\n",
      "Skipping already processed Dataset Pair ID: 19\n",
      "Skipping already processed Dataset Pair ID: 20\n",
      "Skipping already processed Dataset Pair ID: 21\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Skipping already processed Dataset Pair ID: 23\n",
      "Skipping already processed Dataset Pair ID: 24\n",
      "Skipping already processed Dataset Pair ID: 25\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n",
      "Done.\n",
      "Hitting the requirements summarization endpoint...\n",
      "Done.\n",
      "Hitting the comparison summarization endpoint...\n",
      "Done.\n",
      "\n",
      "Hitting the code summarization endpoint...\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/syntropy-app-KmLYymlh-py3.13/lib/python3.13/site-packages/requests/models.py:974\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    973\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m974\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    976\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    977\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:345\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    343\u001b[39m \n\u001b[32m    344\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:363\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     56\u001b[39m             \u001b[38;5;66;03m# time.sleep(5)\u001b[39;00m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mProcessing complete.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43mrun_syntropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mrun_syntropy\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Hit the code summarization endpoint\u001b[39;00m\n\u001b[32m     24\u001b[39m code_response = requests.post(CODE_SUMMARIZATION_URL, json={\u001b[33m\"\u001b[39m\u001b[33mdiffs\u001b[39m\u001b[33m\"\u001b[39m: code_block})\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m code_summary = \u001b[43mcode_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(result_path, \u001b[33m\"\u001b[39m\u001b[33mcode_summarization.json\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     27\u001b[39m     json.dump(code_summary, f, indent=\u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/syntropy-app-KmLYymlh-py3.13/lib/python3.13/site-packages/requests/models.py:978\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    974\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson.loads(\u001b[38;5;28mself\u001b[39m.text, **kwargs)\n\u001b[32m    975\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    976\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    977\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m978\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Load CSV and process each row\n",
    "\n",
    "def run_syntropy():\n",
    "    with open(\"dataset.csv\", \"r\", newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            # print(row.keys())\n",
    "            if not \"Dataset Pair ID\" in row.keys():\n",
    "                continue\n",
    "            dataset_pair_id = row[\"Dataset Pair ID\"]\n",
    "            code_block = row[\"Code Block(s)\"]\n",
    "            requirements = row[\"Requirements\"]\n",
    "    \n",
    "            if is_already_processed(dataset_pair_id):\n",
    "                print(f\"Skipping already processed Dataset Pair ID: {dataset_pair_id}\")\n",
    "                continue\n",
    "    \n",
    "            # Create a directory for each dataset_pair_id\n",
    "            result_path = os.path.join(RESULTS_DIR, dataset_pair_id)\n",
    "            os.makedirs(result_path, exist_ok=True)\n",
    "    \n",
    "            print('Hitting the code summarization endpoint...')\n",
    "            # Hit the code summarization endpoint\n",
    "            code_response = requests.post(CODE_SUMMARIZATION_URL, json={\"diffs\": code_block})\n",
    "            code_summary = code_response.json()\n",
    "            with open(os.path.join(result_path, \"code_summarization.json\"), \"w\", encoding='utf-8') as f:\n",
    "                json.dump(code_summary, f, indent=2)\n",
    "    \n",
    "            print('Done.')\n",
    "    \n",
    "            print('Hitting the requirements summarization endpoint...')\n",
    "            # Hit the requirements summarization endpoint\n",
    "            requirements_response = requests.post(REQUIREMENTS_SUMMARIZATION_URL, json={\"requirements\": requirements})\n",
    "            requirements_summary = requirements_response.json()\n",
    "            with open(os.path.join(result_path, \"requirements_summarization.json\"), \"w\", encoding='utf-8') as f:\n",
    "                json.dump(requirements_summary, f, indent=2)\n",
    "    \n",
    "            print('Done.')\n",
    "    \n",
    "            print('Hitting the comparison summarization endpoint...')\n",
    "            # Hit the comparison summarization endpoint\n",
    "            comparison_response = requests.post(\n",
    "                COMPARISON_SUMMARIZATION_URL,\n",
    "                json={\n",
    "                    \"code_summary\": code_summary,\n",
    "                    \"requirements_summary\": requirements_summary\n",
    "                }\n",
    "            )\n",
    "            comparison_summary = comparison_response.json()\n",
    "            with open(os.path.join(result_path, \"comparison_summarization.json\"), \"w\", encoding='utf-8') as f:\n",
    "                json.dump(comparison_summary, f, indent=2)\n",
    "    \n",
    "            print('Done.')\n",
    "            print()\n",
    "    \n",
    "            # time.sleep(5)\n",
    "    \n",
    "    print(\"Processing complete.\")\n",
    "\n",
    "run_syntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "00fbc0ad-de54-482d-b920-5ce44d3616c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_singleton_analysis(dp_id):\n",
    "    with open(\"dataset.csv\", \"r\", newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        processed = False\n",
    "        for row in reader:\n",
    "            #print(row.keys())\n",
    "            if not \"Dataset Pair ID\" in row.keys():\n",
    "                continue\n",
    "                \n",
    "            dataset_pair_id = row[\"Dataset Pair ID\"]\n",
    "            code_block = row[\"Code Block(s)\"]\n",
    "            requirements = row[\"Requirements\"]\n",
    "    \n",
    "            if str(dp_id) != dataset_pair_id:\n",
    "                continue\n",
    "    \n",
    "            print('---REQUIREMENTS:---')\n",
    "            print(requirements)\n",
    "            print()\n",
    "            \n",
    "            print('---CODE BLOCK:---')\n",
    "            print(code_block)\n",
    "            print()\n",
    "    \n",
    "            print('---SYNTHESIS:---')\n",
    "            \n",
    "            summary_file = \"comparison_summarization.json\"\n",
    "            \n",
    "            json_filename = f'{RESULTS_DIR}/{dataset_pair_id}/{summary_file}'\n",
    "            try:\n",
    "                with open(json_filename) as f:\n",
    "                    d = json.load(f)\n",
    "                    print(json.dumps(d, indent=4))\n",
    "\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"Synthesis for Dataset Pair ID has not been processed yet: {dp_id}\")\n",
    "                print()\n",
    "                \n",
    "            processed = True\n",
    "    if not processed:\n",
    "        print(f\"Dataset Pair ID {dp_id} has not been processed yet, or does not exist.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1a61e91e-285f-4b7d-bb7d-7017bbc844a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjective_analyses = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac563de-0316-4e0d-85e3-19724ce510f6",
   "metadata": {},
   "source": [
    "# Subjective Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a10dd54-b3a5-4bad-88a9-84306c971ad4",
   "metadata": {},
   "source": [
    "For each dataset pair, we will run a subjective anlalysis that will be a binary evaluation of whether the model performed as expected."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf6e9ef5-e7a4-4646-a27b-8436ea9e9fc9",
   "metadata": {},
   "source": [
    "Example:\n",
    "\n",
    "subjective_analyses[pair_id] = {\n",
    "    'core_business_functionality': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "    \n",
    "    'structural_and_modular_requirements': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "    \n",
    "    'performance_and_scalability_criteria': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "    \n",
    "    'data_handling_and_integrity': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "        \n",
    "    'error_handling_and_user_experience': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "        \n",
    "    'efficiency_requirements_for_product_use_cases': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "        \n",
    "    'readability_maintainability_and_team_adoption': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "        \n",
    "    'testing_and_validation_criteria': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "        \n",
    "    'external_dependencies_and_integrations': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "        \n",
    "    'security_standards_and_threat_mitigation': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "        \n",
    "    'compliance_and_regulatory_considerations': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "        \n",
    "    'adherence_to_standards_and_best_practices': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': }}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c052d1-39b4-49e0-9c9f-6ee58d6c4ae8",
   "metadata": {},
   "source": [
    "## Dataset Pair ID 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "28bdc97e-e4cf-4f2b-a40d-8c7378b424cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---REQUIREMENTS:---\n",
      "The application must enforce data immutability for critical objects and implement a custom serialization mechanism to ensure secure data exchange. Integration with our custom build system is required, and efforts should be made to improve existing documentation.\n",
      "\n",
      "---CODE BLOCK:---\n",
      "# Custom build system integration\n",
      "# Note: This code lacks thorough documentation.\n",
      "class ImmutableData:\n",
      "    def __init__(self, data):\n",
      "        self._data = tuple(data)  # using immutable tuple to store data\n",
      "\n",
      "    def serialize(self):\n",
      "        # Custom serialization: convert data to a comma-separated string\n",
      "        return ','.join(map(str, self._data))\n",
      "\n",
      "    @classmethod\n",
      "    def deserialize(cls, data_str):\n",
      "        # Custom deserialization\n",
      "        data = tuple(data_str.split(','))\n",
      "        return cls(data)\n",
      "\n",
      "data_obj = ImmutableData([1, 2, 3])\n",
      "serialized = data_obj.serialize()\n",
      "new_obj = ImmutableData.deserialize(serialized)\n",
      "print(serialized)\n",
      "\n",
      "---SYNTHESIS:---\n",
      "{\n",
      "    \"core_business_functionality\": {\n",
      "        \"did_right\": \"The code contributes to the product by enabling a simple way to store and retrieve data in a specific format using custom serialization/deserialization.\",\n",
      "        \"did_wrong\": \"Without specific requirements about the application's purpose, it is impossible to determine if the implementation aligns with the core business functionality.\",\n",
      "        \"ambiguous\": \"It's unclear how well the comma-separated string format suits the application needs without knowing the data's nature and use cases.\"\n",
      "    },\n",
      "    \"structural_and_modular_requirements\": {\n",
      "        \"did_right\": \"The single class structure is reasonable for a simple data handling task.\",\n",
      "        \"did_wrong\": \"Modularity is limited; the serialization/deserialization logic could be in a separate module if reused elsewhere.\",\n",
      "        \"ambiguous\": \"Whether the single-class structure is appropriate depends on the overall application architecture, which is unknown.\"\n",
      "    },\n",
      "    \"performance_and_scalability_criteria\": {\n",
      "        \"did_right\": \"Performance is likely not an issue for small datasets.\",\n",
      "        \"did_wrong\": \"The comma-separated string serialization method may become a bottleneck with large datasets.\",\n",
      "        \"ambiguous\": \"Scalability performance remains undetermined until testing with larger datasets is done.\"\n",
      "    },\n",
      "    \"data_handling_and_integrity\": {\n",
      "        \"did_right\": \"Data immutability is enforced using a tuple.\",\n",
      "        \"did_wrong\": \"Error handling for malformed serialized strings could be improved.\",\n",
      "        \"ambiguous\": \"Robustness is dependent on input string validation during deserialization. The validation is implicit instead of explicit.\"\n",
      "    },\n",
      "    \"error_handling_and_user_experience\": {\n",
      "        \"did_right\": \"N/A\",\n",
      "        \"did_wrong\": \"Minimal error handling. Exceptions during deserialization are not caught which can lead to crashes or data corruption.\",\n",
      "        \"ambiguous\": \"User impact of errors is uncertain without knowing the application's user interface and workflow.\"\n",
      "    },\n",
      "    \"efficiency_requirements_for_product_use_cases\": {\n",
      "        \"did_right\": \"Efficiency is adequate for small datasets.\",\n",
      "        \"did_wrong\": \"Alternative serialization methods might be required for larger datasets.\",\n",
      "        \"ambiguous\": \"The efficiency appropriateness depends on the specific use cases and data sizes, which are unknown.\"\n",
      "    },\n",
      "    \"readability_maintainability_and_team_adoption\": {\n",
      "        \"did_right\": \"The code is reasonably readable and maintainable in its current form.\",\n",
      "        \"did_wrong\": \"Missing docstrings and less descriptive variable names hinder readability and maintainability.\",\n",
      "        \"ambiguous\": \"Team adoption is dependent on proper documentation and coding style consistency which are not currently addressed.\"\n",
      "    },\n",
      "    \"testing_and_validation_criteria\": {\n",
      "        \"did_right\": \"N/A\",\n",
      "        \"did_wrong\": \"No unit tests are provided to cover various scenarios and edge cases. The provided example is not sufficient for validation.\",\n",
      "        \"ambiguous\": \"Validation is reliant on unknown product requirements, and test strategy is not clear.\"\n",
      "    },\n",
      "    \"external_dependencies_and_integrations\": {\n",
      "        \"did_right\": \"No external dependencies besides Python built-in libraries.\",\n",
      "        \"did_wrong\": \"Integration with a custom build system is a required feature that has not been implemented.\",\n",
      "        \"ambiguous\": \"The method of integration is not described.\"\n",
      "    },\n",
      "    \"security_standards_and_threat_mitigation\": {\n",
      "        \"did_right\": \"Custom serialization mechanism aids in secure data exchange.\",\n",
      "        \"did_wrong\": \"No explicit encryption or validation to prevent injection attacks from untrusted sources.\",\n",
      "        \"ambiguous\": \"Further security is dependent on sensitive data handled.\"\n",
      "    },\n",
      "    \"compliance_and_regulatory_considerations\": {\n",
      "        \"did_right\": \"N/A\",\n",
      "        \"did_wrong\": \"No explicit compliance steps are taken in the code.\",\n",
      "        \"ambiguous\": \"The need for compliance is dependent on data sensitivity, such as PII.\"\n",
      "    },\n",
      "    \"adherence_to_standards_and_best_practices\": {\n",
      "        \"did_right\": \"Basic Python coding conventions are followed.\",\n",
      "        \"did_wrong\": \"Missing docstrings and style guide adherence.\",\n",
      "        \"ambiguous\": \"Style consistency is uncertain.\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pair_id = \"1\"\n",
    "run_singleton_analysis(pair_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4eb5521a-fe2c-404c-8d4a-067eae8829c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjective_analyses[pair_id] = {\n",
    "    'core_business_functionality': {\n",
    "        'did_right': 1,\n",
    "        'did_wrong': 1,\n",
    "        'ambiguous': 1},\n",
    "    \n",
    "    'structural_and_modular_requirements': {\n",
    "        'did_right': 1,\n",
    "        'did_wrong': 1,\n",
    "        'ambiguous': 1},\n",
    "    \n",
    "    'performance_and_scalability_criteria': {\n",
    "        'did_right': 1,\n",
    "        'did_wrong': 1,\n",
    "        'ambiguous': 1},\n",
    "    \n",
    "    'data_handling_and_integrity': {\n",
    "        'did_right': 1,\n",
    "        'did_wrong': 1,\n",
    "        'ambiguous': 1},\n",
    "        \n",
    "    'error_handling_and_user_experience': {\n",
    "        'did_right': 0,\n",
    "        'did_wrong': 1,\n",
    "        'ambiguous': 1},\n",
    "        \n",
    "    'efficiency_requirements_for_product_use_cases': {\n",
    "        'did_right': 1,\n",
    "        'did_wrong': 1,\n",
    "        'ambiguous': 1},\n",
    "        \n",
    "    'readability_maintainability_and_team_adoption': {\n",
    "        'did_right': 1,\n",
    "        'did_wrong': 1,\n",
    "        'ambiguous': 1},\n",
    "        \n",
    "    'testing_and_validation_criteria': {\n",
    "        'did_right': 0,\n",
    "        'did_wrong': 1,\n",
    "        'ambiguous': 1},\n",
    "        \n",
    "    'external_dependencies_and_integrations': {\n",
    "        'did_right': 1,\n",
    "        'did_wrong': 1,\n",
    "        'ambiguous': 1},\n",
    "        \n",
    "    'security_standards_and_threat_mitigation': {\n",
    "        'did_right': 1,\n",
    "        'did_wrong': 1,\n",
    "        'ambiguous': 1},\n",
    "        \n",
    "    'compliance_and_regulatory_considerations': {\n",
    "        'did_right': 0,\n",
    "        'did_wrong': 1,\n",
    "        'ambiguous': 1},\n",
    "        \n",
    "    'adherence_to_standards_and_best_practices': {\n",
    "        'did_right': 1,\n",
    "        'did_wrong': 1,\n",
    "        'ambiguous': 1}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa06d69-2348-4ae0-b6e4-156a2a7f1ce0",
   "metadata": {},
   "source": [
    "## Dataset Pair ID 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0345317d-0017-4869-93e9-e49e259483f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---REQUIREMENTS:---\n",
      "The system must evaluate numeric inputs through multi-branch logic. Please refactor the current high-cyclomatic complexity into more streamlined conditional flows for improved maintainability.\n",
      "\n",
      "---CODE BLOCK:---\n",
      "def process_value(x):\n",
      "    if x < 0:\n",
      "        result = 'negative'\n",
      "    elif x == 0:\n",
      "        result = 'zero'\n",
      "    elif x > 0 and x < 10:\n",
      "        result = 'small positive'\n",
      "    elif x >= 10 and x < 100:\n",
      "        result = 'medium positive'\n",
      "    else:\n",
      "        result = 'large positive'\n",
      "    return result\n",
      "\n",
      "print(process_value(42))\n",
      "\n",
      "---SYNTHESIS:---\n",
      "{\n",
      "    \"core_business_functionality\": {\n",
      "        \"did_right\": \"The code categorizes numeric input into descriptive strings based on value ranges, fulfilling the core requirement of evaluating numeric inputs based on multi-branch logic.\",\n",
      "        \"did_wrong\": \"The prompt states that the function contributes to the product by providing a way to translate raw numeric data into more human-readable labels. However, the prompt doesn't include the evaluation of the output accuracy and therefore the core business functionality is unmet.\",\n",
      "        \"ambiguous\": \"It's not clear if the categorization logic (the value ranges and their corresponding descriptions) is accurate and complete based on the original requirements, or if it meets all necessary business rules.\"\n",
      "    },\n",
      "    \"structural_and_modular_requirements\": {\n",
      "        \"did_right\": \"N/A\",\n",
      "        \"did_wrong\": \"The code consists of a single function, lacking modularity. The prompt states it needs refactoring to reduce complexity and improve maintainability.\",\n",
      "        \"ambiguous\": \"The extent to which the 'process_value' function increases the cyclomatic complexity is not explicitly mentioned, therefore is ambiguous.\"\n",
      "    },\n",
      "    \"performance_and_scalability_criteria\": {\n",
      "        \"did_right\": \"The code has minimal performance overhead and is unlikely to be a bottleneck for smaller datasets.\",\n",
      "        \"did_wrong\": \"N/A\",\n",
      "        \"ambiguous\": \"Scalability is uncertain; the iterative nature might introduce performance issues with very large datasets. It's unclear if the current performance degrades compared to a potential original implementation (as the performance requirement states 'Performance should not degrade *after refactoring*').\"\n",
      "    },\n",
      "    \"data_handling_and_integrity\": {\n",
      "        \"did_right\": \"The function accepts an integer or float, accommodating numeric inputs.\",\n",
      "        \"did_wrong\": \"The code does not explicitly validate the data type of the input, potentially leading to unexpected behavior if non-numeric values are passed. Data integrity is compromised without validation.\",\n",
      "        \"ambiguous\": \"The requirement mentions 'validation of inputs, if applicable, should be maintained or improved'. It's unclear if there was previous input validation that needs to be maintained.\"\n",
      "    },\n",
      "    \"error_handling_and_user_experience\": {\n",
      "        \"did_right\": \"N/A\",\n",
      "        \"did_wrong\": \"The code lacks explicit error handling. A TypeError will likely halt execution if a non-numeric value is given. This does not provide a graceful user experience.\",\n",
      "        \"ambiguous\": \"The requirement mentions 'providing informative error messages *if appropriate (if the system is user-facing)*'. It is not indicated whether the code is intended to be user facing or not.\"\n",
      "    },\n",
      "    \"efficiency_requirements_for_product_use_cases\": {\n",
      "        \"did_right\": \"The function's efficiency is sufficient for simple categorization tasks.\",\n",
      "        \"did_wrong\": \"N/A\",\n",
      "        \"ambiguous\": \"Efficiency is unclear for performance-critical applications or very large datasets. Whether the current efficiency meets or exceeds the requirements of the product use cases (compared to an older version) is not stated.\"\n",
      "    },\n",
      "    \"readability_maintainability_and_team_adoption\": {\n",
      "        \"did_right\": \"The code is fairly readable due to its simplicity.\",\n",
      "        \"did_wrong\": \"The code lacks comments explaining the purpose and intended usage, which hinders maintainability.\",\n",
      "        \"ambiguous\": \"While somewhat readable, the lack of documentation impacts how easily other developers can understand and adopt the code.\"\n",
      "    },\n",
      "    \"testing_and_validation_criteria\": {\n",
      "        \"did_right\": \"N/A\",\n",
      "        \"did_wrong\": \"The example only prints the result of calling the function once; comprehensive testing is needed for various inputs, boundary conditions, and edge cases. There are no unit tests.\",\n",
      "        \"ambiguous\": \"It is unknown if the existing implementation produces the same results as the original one, as the prompt mentions the need for thorough testing across input ranges.\"\n",
      "    },\n",
      "    \"external_dependencies_and_integrations\": {\n",
      "        \"did_right\": \"The code has no external dependencies.\",\n",
      "        \"did_wrong\": \"N/A\",\n",
      "        \"ambiguous\": \"If the code were to interact with external systems, the documentation of dependencies and integration procedures is missing (but there are no external dependencies at this point).\"\n",
      "    },\n",
      "    \"security_standards_and_threat_mitigation\": {\n",
      "        \"did_right\": \"The code itself presents no obvious security risks, as it only processes numeric inputs.\",\n",
      "        \"did_wrong\": \"N/A\",\n",
      "        \"ambiguous\": \"The need for validation depends on the source of the input. If the input comes from an external source, it might be vulnerable to security exploits.\"\n",
      "    },\n",
      "    \"compliance_and_regulatory_considerations\": {\n",
      "        \"did_right\": \"N/A\",\n",
      "        \"did_wrong\": \"N/A\",\n",
      "        \"ambiguous\": \"Compliance requirements depend on the product's intended use and industry regulations, which are not specified.\"\n",
      "    },\n",
      "    \"adherence_to_standards_and_best_practices\": {\n",
      "        \"did_right\": \"The code generally follows basic Python conventions.\",\n",
      "        \"did_wrong\": \"The code lacks a docstring to describe the function's purpose and parameters. No linters or formatters are used.\",\n",
      "        \"ambiguous\": \"The extent to which the code adheres to modular design principles is unclear (it does not follow them).\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pair_id = \"2\"\n",
    "run_singleton_analysis(pair_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fa758455-c4d4-48f0-84a3-5cfa92ec872b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expression expected after dictionary key and ':' (155827130.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[119]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m'did_right': ,\u001b[39m\n               ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m expression expected after dictionary key and ':'\n"
     ]
    }
   ],
   "source": [
    "subjective_analyses[pair_id] = {\n",
    "    'core_business_functionality': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "    \n",
    "    'structural_and_modular_requirements': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "    \n",
    "    'performance_and_scalability_criteria': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "    \n",
    "    'data_handling_and_integrity': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "        \n",
    "    'error_handling_and_user_experience': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "        \n",
    "    'efficiency_requirements_for_product_use_cases': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "        \n",
    "    'readability_maintainability_and_team_adoption': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "        \n",
    "    'testing_and_validation_criteria': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "        \n",
    "    'external_dependencies_and_integrations': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "        \n",
    "    'security_standards_and_threat_mitigation': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "        \n",
    "    'compliance_and_regulatory_considerations': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': },\n",
    "        \n",
    "    'adherence_to_standards_and_best_practices': {\n",
    "        'did_right': ,\n",
    "        'did_wrong': ,\n",
    "        'ambiguous': }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b5866-6fbf-406b-b276-b7abcb886592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
